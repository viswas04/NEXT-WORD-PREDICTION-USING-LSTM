{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from transformers import pipeline\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess dataset\n",
    "DATASET_PATH = 'metamorphosis_clean.txt'\n",
    "with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "    corpus = f.read().lower().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input sequences\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        input_sequences.append(token_list[:i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "max_sequence_length = max(len(seq) for seq in input_sequences)\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
    "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "y = np.array(y)  # No need for one-hot encoding with sparse categorical loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\venka\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Build Improved BiLSTM Model\n",
    "model = Sequential([\n",
    "    Embedding(total_words, 256, input_length=max_sequence_length - 1),\n",
    "    Bidirectional(LSTM(256, return_sequences=True)),\n",
    "    Dropout(0.2),\n",
    "    Bidirectional(LSTM(128)),\n",
    "    Dropout(0.2),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 148ms/step - accuracy: 0.0490 - loss: 6.3171\n",
      "Epoch 2/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 145ms/step - accuracy: 0.0669 - loss: 5.6950\n",
      "Epoch 3/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 145ms/step - accuracy: 0.0960 - loss: 5.4269\n",
      "Epoch 4/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 142ms/step - accuracy: 0.1253 - loss: 5.1212\n",
      "Epoch 5/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 142ms/step - accuracy: 0.1369 - loss: 4.9605\n",
      "Epoch 6/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 142ms/step - accuracy: 0.1465 - loss: 4.8021\n",
      "Epoch 7/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 142ms/step - accuracy: 0.1536 - loss: 4.6566\n",
      "Epoch 8/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 142ms/step - accuracy: 0.1578 - loss: 4.5384\n",
      "Epoch 9/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 141ms/step - accuracy: 0.1617 - loss: 4.4190\n",
      "Epoch 10/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 126ms/step - accuracy: 0.1744 - loss: 4.2941\n",
      "Epoch 11/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 131ms/step - accuracy: 0.1848 - loss: 4.1398\n",
      "Epoch 12/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 118ms/step - accuracy: 0.2015 - loss: 4.0100\n",
      "Epoch 13/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 116ms/step - accuracy: 0.2108 - loss: 3.8802\n",
      "Epoch 14/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 114ms/step - accuracy: 0.2195 - loss: 3.7609\n",
      "Epoch 15/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 113ms/step - accuracy: 0.2300 - loss: 3.6433\n",
      "Epoch 16/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 138ms/step - accuracy: 0.2563 - loss: 3.4964\n",
      "Epoch 17/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 127ms/step - accuracy: 0.2688 - loss: 3.3532\n",
      "Epoch 18/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 124ms/step - accuracy: 0.2970 - loss: 3.2199\n",
      "Epoch 19/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 124ms/step - accuracy: 0.3158 - loss: 3.0929\n",
      "Epoch 20/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 126ms/step - accuracy: 0.3318 - loss: 2.9674\n",
      "Epoch 21/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 125ms/step - accuracy: 0.3575 - loss: 2.8235\n",
      "Epoch 22/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 126ms/step - accuracy: 0.3846 - loss: 2.6982\n",
      "Epoch 23/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 124ms/step - accuracy: 0.4070 - loss: 2.5733\n",
      "Epoch 24/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 125ms/step - accuracy: 0.4275 - loss: 2.4503\n",
      "Epoch 25/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 135ms/step - accuracy: 0.4613 - loss: 2.3280\n",
      "Epoch 26/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 141ms/step - accuracy: 0.4907 - loss: 2.1849\n",
      "Epoch 27/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 117ms/step - accuracy: 0.5070 - loss: 2.0889\n",
      "Epoch 28/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 111ms/step - accuracy: 0.5270 - loss: 1.9893\n",
      "Epoch 29/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 111ms/step - accuracy: 0.5488 - loss: 1.8765\n",
      "Epoch 30/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 111ms/step - accuracy: 0.5740 - loss: 1.7571\n",
      "Epoch 31/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 114ms/step - accuracy: 0.5926 - loss: 1.6732\n",
      "Epoch 32/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 111ms/step - accuracy: 0.6165 - loss: 1.5771\n",
      "Epoch 33/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 110ms/step - accuracy: 0.6430 - loss: 1.4746\n",
      "Epoch 34/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 111ms/step - accuracy: 0.6558 - loss: 1.4047\n",
      "Epoch 35/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 114ms/step - accuracy: 0.6687 - loss: 1.3411\n",
      "Epoch 36/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 113ms/step - accuracy: 0.6954 - loss: 1.2467\n",
      "Epoch 37/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 118ms/step - accuracy: 0.7085 - loss: 1.1878\n",
      "Epoch 38/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 117ms/step - accuracy: 0.7201 - loss: 1.1279\n",
      "Epoch 39/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 116ms/step - accuracy: 0.7371 - loss: 1.0687\n",
      "Epoch 40/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 116ms/step - accuracy: 0.7470 - loss: 0.9995\n",
      "Epoch 41/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 117ms/step - accuracy: 0.7623 - loss: 0.9487\n",
      "Epoch 42/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 113ms/step - accuracy: 0.7669 - loss: 0.9264\n",
      "Epoch 43/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 110ms/step - accuracy: 0.7933 - loss: 0.8413\n",
      "Epoch 44/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 111ms/step - accuracy: 0.7950 - loss: 0.8185\n",
      "Epoch 45/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 111ms/step - accuracy: 0.8022 - loss: 0.7772\n",
      "Epoch 46/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 115ms/step - accuracy: 0.8053 - loss: 0.7584\n",
      "Epoch 47/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 117ms/step - accuracy: 0.8122 - loss: 0.7385\n",
      "Epoch 48/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 111ms/step - accuracy: 0.8286 - loss: 0.6804\n",
      "Epoch 49/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 111ms/step - accuracy: 0.8364 - loss: 0.6469\n",
      "Epoch 50/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 111ms/step - accuracy: 0.8347 - loss: 0.6460\n",
      "Epoch 51/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 111ms/step - accuracy: 0.8400 - loss: 0.6255\n",
      "Epoch 52/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 111ms/step - accuracy: 0.8511 - loss: 0.5958\n",
      "Epoch 53/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 95ms/step - accuracy: 0.8519 - loss: 0.5702\n",
      "Epoch 54/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 90ms/step - accuracy: 0.8574 - loss: 0.5539\n",
      "Epoch 55/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 91ms/step - accuracy: 0.8618 - loss: 0.5315\n",
      "Epoch 56/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 108ms/step - accuracy: 0.8607 - loss: 0.5354\n",
      "Epoch 57/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 112ms/step - accuracy: 0.8631 - loss: 0.5136\n",
      "Epoch 58/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 111ms/step - accuracy: 0.8647 - loss: 0.5094\n",
      "Epoch 59/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 119ms/step - accuracy: 0.8732 - loss: 0.4801\n",
      "Epoch 60/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 115ms/step - accuracy: 0.8738 - loss: 0.4821\n",
      "Epoch 61/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 120ms/step - accuracy: 0.8794 - loss: 0.4552\n",
      "Epoch 62/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 121ms/step - accuracy: 0.8841 - loss: 0.4416\n",
      "Epoch 63/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 114ms/step - accuracy: 0.8786 - loss: 0.4479\n",
      "Epoch 64/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 111ms/step - accuracy: 0.8777 - loss: 0.4470\n",
      "Epoch 65/65\n",
      "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 112ms/step - accuracy: 0.8854 - loss: 0.4179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20296aed460>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "epochs = 65\n",
    "model.fit(X, y, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training completed! Model and tokenizer saved.\n"
     ]
    }
   ],
   "source": [
    "# Save model and tokenizer\n",
    "model.save('bilstm_model.h5')\n",
    "with open('tokenizer1.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "print(\"✅ Training completed! Model and tokenizer saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ BiLSTM model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load BiLSTM Model\n",
    "bilstm_model = load_model('bilstm_model.h5')\n",
    "print(\"✅ BiLSTM model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tokenizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "with open('tokenizer1.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "print(\"✅ Tokenizer loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\venka\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\venka\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Load BERT fill-mask pipeline\n",
    "fill_mask = pipeline(\"fill-mask\", model=\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset vocabulary\n",
    "if os.path.exists(DATASET_PATH):\n",
    "    with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "        dataset_words = set(f.read().split())\n",
    "else:\n",
    "    dataset_words = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inappropriate words filter\n",
    "BAD_WORDS = {\"damn\", \"hell\", \"shit\", \"fuck\", \"bitch\", \"bastard\", \"ass\", \"asshole\", \"dumbass\", \"jackass\", \n",
    "             \"motherfucker\", \"cock\", \"piss\", \"crap\", \"slut\", \"whore\", \"dick\", \"cunt\", \"nigger\", \n",
    "             \"retard\", \"faggot\", \"twat\", \"wanker\", \"moron\", \"idiot\", \"stupid\"}\n",
    "\n",
    "# Ensure valid words\n",
    "def is_valid_word(word):\n",
    "    return word.lower() not in BAD_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict next word using BiLSTM\n",
    "def predict_next_word_bilstm(text):\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length-1, padding='pre')\n",
    "    prediction = bilstm_model.predict(padded_sequence)\n",
    "    predicted_word = tokenizer.index_word.get(np.argmax(prediction), \"unknown\")\n",
    "    return predicted_word if is_valid_word(predicted_word) else \"[filtered]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict next word using BERT\n",
    "def predict_next_word_bert(text):\n",
    "    masked_text = text + \" [MASK].\"\n",
    "    predictions = fill_mask(masked_text)\n",
    "    for pred in predictions:\n",
    "        word = pred['token_str']\n",
    "        if is_valid_word(word):\n",
    "            return word\n",
    "    return \"[filtered]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(text):\n",
    "    words = text.split()\n",
    "    last_word = words[-1] if words else \"\"\n",
    "    if last_word in dataset_words:\n",
    "        return predict_next_word_bilstm(text)\n",
    "    else:\n",
    "        new_word = predict_next_word_bert(text)\n",
    "        if new_word != \"[filtered]\":\n",
    "            predicted_sentence = text + \" \" + new_word\n",
    "            dataset_words.update(predicted_sentence.split())\n",
    "            with open(DATASET_PATH, 'a', encoding='utf-8') as f:\n",
    "                f.write(\"\\n\" + predicted_sentence.strip())  # Save entire sentence\n",
    "        return new_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict multiple words\n",
    "def Predict_Next_Words(text, num_words):\n",
    "    predicted_sentence = text\n",
    "    for _ in range(num_words):\n",
    "        next_word = predict_next_word(predicted_sentence)\n",
    "        predicted_sentence += \" \" + next_word.strip()\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "🔹 Input: The book was\n",
      "✅ Predicted Sentence: The book was as well as if they\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "if __name__ == \"__main__\":\n",
    "    input_text = \"The book was\"\n",
    "    num_predictions = 5\n",
    "    result = Predict_Next_Words(input_text, num_predictions)\n",
    "    print(f\"\\n🔹 Input: {input_text}\\n✅ Predicted Sentence: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Error: Please enter a valid number for the number of words to predict.\n"
     ]
    }
   ],
   "source": [
    "# Take user input\n",
    "user_input = input(\"Enter a starting phrase: \")\n",
    "num_words_to_predict = input(\"Enter the number of words to predict: \")\n",
    "\n",
    "# Ensure the second input is converted to an integer\n",
    "try:\n",
    "\tnum_words_to_predict = int(num_words_to_predict)\n",
    "\tpredicted_sentence = Predict_Next_Words(user_input, num_words_to_predict)\n",
    "\tprint(f\"\\n🔹 Input: {user_input}\\n✅ Predicted Sentence: {predicted_sentence}\")\n",
    "except ValueError:\n",
    "\tprint(\"❌ Error: Please enter a valid number for the number of words to predict.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
